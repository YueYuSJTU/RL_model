# PPO-Transformer 参数
policy: "MlpPolicy"
learning_rate: 1.0e-4
device: "cuda"
verbose: 1
n_steps: 2048
batch_size: 128
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
clip_range_vf: null
ent_coef: 0.0
vf_coef: 0.5
max_grad_norm: 0.5

policy_kwargs:
  features_extractor_class: "src.agents.transformer.trans_nn:TransformerFeatureExtractor"
  features_extractor_kwargs:
    features_dim: 256
  share_features_extractor: True
  net_arch: 
    [256]